# å…«å¡åˆ†å¸ƒå¼è®­ç»ƒæŒ‡å— (8-GPU DDP Training Guide)

## ğŸ¯ è®­ç»ƒç­–ç•¥ï¼šæ–¹æ¡ˆ Bï¼ˆæ¯å¡ç‹¬ç«‹é‡‡æ ·ï¼Œæ¢¯åº¦ç´¯åŠ ï¼‰

æœ¬ DDP å®ç°é‡‡ç”¨**æ–¹æ¡ˆ B**ï¼Œè¿™æ„å‘³ç€ï¼š

### æ ¸å¿ƒåŸç†

```
å•å¡è®­ç»ƒ:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  é‡‡æ · batch (128)    â”‚
  â”‚  è®¡ç®—æ¢¯åº¦            â”‚
  â”‚  ä¼˜åŒ–å™¨æ›´æ–°          â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  æ¯ episode: 1 æ¬¡æ¢¯åº¦æ›´æ–°

8å¡åˆ†å¸ƒå¼ (æ–¹æ¡ˆB):
  GPU0              GPU1              GPU2        ...      GPU7
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚é‡‡æ · 128  â”‚      â”‚é‡‡æ · 128  â”‚      â”‚é‡‡æ · 128  â”‚        â”‚é‡‡æ · 128  â”‚
  â”‚è®¡ç®—æ¢¯åº¦1 â”‚      â”‚è®¡ç®—æ¢¯åº¦2 â”‚      â”‚è®¡ç®—æ¢¯åº¦3 â”‚   ...  â”‚è®¡ç®—æ¢¯åº¦8 â”‚
  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚                  â”‚                 â”‚                    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
                    DDP å¹³å‡æ¢¯åº¦
                 (g1+g2+...+g8)/8
                           â”‚
                     è°ƒæ•´å­¦ä¹ ç‡ Ã— 8
                    è¡¥å¿æ¢¯åº¦å¹³å‡
                           â”‚
                      ä¼˜åŒ–å™¨æ›´æ–°
                           â–¼
              ç­‰ä»·äº batch_size=1024 çš„å•å¡è®­ç»ƒ

  æ¯ episode: 8 æ¬¡æ¢¯åº¦æ›´æ–°ï¼
```

### å…·ä½“è®¡ç®—

| æŒ‡æ ‡ | å•å¡ | 8å¡(æ–¹æ¡ˆB) |
|------|------|-----------|
| batch_size | 128 | 128 (æ¯å¡) |
| æœ‰æ•ˆ batch_size | 128 | 1024 |
| æ¢¯åº¦æ›´æ–°æ•° | 1x | 8x |
| å­¦ä¹ ç‡ | 0.0003 | 0.0024 |
| å•æ­¥æ¢¯åº¦ | g | (g1+g2+...+g8)/8 |
| ä¼˜åŒ–å™¨æ›´æ–° | Î¸ -= lr*g | Î¸ -= lr*8*(g1+g2+...+g8)/8 = Î¸ -= lr*(g1+...+g8) |

### ä¼˜ç¼ºç‚¹

âœ… **ä¼˜ç‚¹**ï¼š
- æ¢¯åº¦æ›´æ–°é¢‘ç‡ 8 å€
- å¯èƒ½æ›´å¿«æ”¶æ•›
- å……åˆ†åˆ©ç”¨å¤š GPU

âŒ **ç¼ºç‚¹**ï¼š
- æ”¹å˜äº†è®­ç»ƒåŠ¨æ€ï¼ˆæœ‰æ•ˆ batch size å˜å¤§ï¼‰
- è¶…å‚å¯èƒ½éœ€è¦å¾®è°ƒ
- æ”¶æ•›è½¨è¿¹ä¸å•å¡ä¸åŒ

---

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•åœ¨å¤šä¸ª GPUï¼ˆæ¨è 8 å¼ ï¼‰ä¸Šè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒã€‚

This guide explains how to perform distributed training on multiple GPUs (recommended 8).

---

## å¿«é€Ÿå¼€å§‹ (Quick Start)

### 1. ç¯å¢ƒé…ç½®

```bash
# åˆ›å»º conda ç¯å¢ƒ
conda create -n snake3v3 python=3.7.5
conda activate snake3v3

# å®‰è£…ä¾èµ–ï¼ˆåŒ…å« torchï¼‰
pip install -r requirements.txt

# éªŒè¯ GPU å’Œ torch å®‰è£…
python -c "import torch; print(f'CUDA Available: {torch.cuda.is_available()}'); print(f'GPU Count: {torch.cuda.device_count()}')"
```

### 2. è¿è¡Œåˆ†å¸ƒå¼è®­ç»ƒ

#### æ–¹æ³• Aï¼šä½¿ç”¨è„šæœ¬å¯åŠ¨ï¼ˆæ¨èï¼‰

```bash
# åŸºç¡€å‘½ä»¤ - è‡ªåŠ¨æ£€æµ‹ GPU æ•°é‡ï¼Œ8å¡è®­ç»ƒçº¦6250 episodesï¼ˆ= å•å¡50k/8ï¼‰
chmod +x train_ddp.sh
./train_ddp.sh

# å¦‚æœè¦æ›´å¤š episodesï¼ˆä¼šæ›´å¤šè®¡ç®—ï¼‰
./train_ddp.sh --max_episodes 12500

# è‡ªå®šä¹‰å‚æ•°
./train_ddp.sh --max_episodes 6250 --epsilon 0.8 --opponent_difficulty_strategy curriculum
```

#### æ–¹æ³• Bï¼šç›´æ¥ä½¿ç”¨ torchrun

```bash
# 8 å¡è®­ç»ƒï¼ˆé»˜è®¤ 6250 episodes = å•å¡ 50k/8ï¼‰
torchrun --nproc_per_node=8 rl_trainer/main_ddp.py

# å¦‚æœè¦æ›´å¤š episodesï¼ˆè®¡ç®—é‡æ›´å¤§ï¼‰
torchrun --nproc_per_node=8 rl_trainer/main_ddp.py --max_episodes 12500

# è‡ªå®šä¹‰å‚æ•°
torchrun --nproc_per_node=8 rl_trainer/main_ddp.py --max_episodes 6250 --batch_size 128

# åªç”¨ 4 å¡ï¼ˆå¦‚æœ GPU ä¸è¶³ï¼‰
torchrun --nproc_per_node=4 rl_trainer/main_ddp.py
```

#### æ–¹æ³• Cï¼šæ‰‹åŠ¨æŒ‡å®š GPUï¼ˆç”¨äºç‰¹å®š GPU è®¾å¤‡ï¼‰

```bash
# ä½¿ç”¨ç‰¹å®šçš„ GPU (æ¯”å¦‚ GPU 2-7)
CUDA_VISIBLE_DEVICES=2,3,4,5,6,7 torchrun --nproc_per_node=6 rl_trainer/main_ddp.py
```

---

## æ–‡ä»¶è¯´æ˜

### æ–°å¢æ–‡ä»¶

| æ–‡ä»¶ | è¯´æ˜ |
|-----|------|
| `rl_trainer/algo/ddpg_ddp.py` | DDP ç‰ˆæœ¬çš„ DDPG ç®—æ³•å®ç° |
| `rl_trainer/main_ddp.py` | DDP ç‰ˆæœ¬çš„è®­ç»ƒå…¥å£è„šæœ¬ |
| `train_ddp.sh` | å…«å¡è®­ç»ƒå¯åŠ¨è„šæœ¬ |
| `README_DDP.md` | æœ¬æ–‡ä»¶ |

### åŸæœ‰æ–‡ä»¶ï¼ˆæ— æ”¹åŠ¨ï¼‰

æ‰€æœ‰åŸå§‹æ–‡ä»¶ä¿æŒä¸å˜ï¼ŒåŒ…æ‹¬ï¼š
- `rl_trainer/main.py` - å•å¡ç‰ˆæœ¬
- `rl_trainer/algo/ddpg.py` - å•å¡ç‰ˆæœ¬
- å…¶ä»–æ‰€æœ‰æ–‡ä»¶

---

## è®­ç»ƒå‚æ•°

DDP ç‰ˆæœ¬æ”¯æŒæ‰€æœ‰åŸå§‹å‚æ•°ï¼Œè®­ç»ƒé€»è¾‘å®Œå…¨ç›¸åŒã€‚

### å¸¸ç”¨å‚æ•°

```bash
--max_episodes 6250            # æœ€å¤§è®­ç»ƒå›åˆæ•° (default: 6250 = å•å¡50k/8, ä¿æŒæ¢¯åº¦æ›´æ–°æ•°ç›¸åŒ)
--batch_size 128               # æ‰¹å¤„ç†å¤§å° (default: 128)
--epsilon 0.5                  # åˆå§‹æ¢ç´¢ç‡ (default: 0.5)
--epsilon_speed 0.9995         # epsilon è¡°å‡é€Ÿåº¦ (default: 0.9995)
--a_lr 0.0003                  # Actor å­¦ä¹ ç‡ (default: 0.0003)
--c_lr 0.0003                  # Critic å­¦ä¹ ç‡ (default: 0.0003)
--gamma 0.99                   # æŠ˜æ‰£å› å­ (default: 0.99)
--tau 0.01                     # è½¯æ›´æ–°ç³»æ•° (default: 0.01)
--save_interval 1000           # æ¨¡å‹ä¿å­˜é—´éš” (default: 1000)

# å¯¹æ‰‹éš¾åº¦è°ƒåº¦
--opponent_difficulty_strategy curriculum   # linear/exponential/curriculum
--enable_opponent_evasion                   # å¯ç”¨èº²é¿å‹å¯¹æ‰‹ (å¢åŠ è®¡ç®—)
--opponent_evasion_start_episode 40000     # èº²é¿å¯¹æ‰‹å¯ç”¨çš„ episode (default: 40000)

# æ¨¡å‹åŠ è½½
--load_model                   # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
--load_model_run 2             # åŠ è½½çš„ run å·
--load_model_run_episode 4000  # åŠ è½½çš„ episode
```

### å®Œæ•´ç¤ºä¾‹

```bash
# é»˜è®¤è®¾ç½®ï¼ˆ8å¡ï¼Œ6250 episodes = å•å¡50k/8 çš„æ¢¯åº¦æ›´æ–°æ•°ï¼‰
torchrun --nproc_per_node=8 rl_trainer/main_ddp.py

# å¦‚æœè¦åŠ å€è®¡ç®—ï¼ˆ12500 episodesï¼‰
torchrun --nproc_per_node=8 rl_trainer/main_ddp.py \
  --max_episodes 12500 \
  --opponent_difficulty_strategy curriculum \
  --save_interval 500

# ä»å·²æœ‰æ¨¡å‹ç»§ç»­è®­ç»ƒ
torchrun --nproc_per_node=8 rl_trainer/main_ddp.py \
  --load_model \
  --load_model_run 1 \
  --load_model_run_episode 6250 \
  --max_episodes 6250

# å¯ç”¨èº²é¿å‹å¯¹æ‰‹ï¼ˆè®¡ç®—å¼€é”€å¤§ï¼‰
torchrun --nproc_per_node=8 rl_trainer/main_ddp.py \
  --max_episodes 6250 \
  --enable_opponent_evasion \
  --opponent_evasion_start_episode 5000
```

---

## å…³é”®ç‰¹æ€§

### 1. è‡ªåŠ¨ GPU åˆ†é…

DDP ç‰ˆæœ¬è‡ªåŠ¨åˆ†é…æ¯ä¸ªè¿›ç¨‹åˆ°ä¸åŒçš„ GPUï¼š
- GPU 0 â†’ è¿›ç¨‹ 0ï¼ˆrank 0ï¼‰
- GPU 1 â†’ è¿›ç¨‹ 1ï¼ˆrank 1ï¼‰
- ...
- GPU 7 â†’ è¿›ç¨‹ 7ï¼ˆrank 7ï¼‰

### 2. æ¢¯åº¦åŒæ­¥

- æ‰€æœ‰è¿›ç¨‹åœ¨æ¯æ¬¡ `backward()` åè‡ªåŠ¨åŒæ­¥æ¢¯åº¦
- ä¼˜åŒ–å™¨æ›´æ–°åŸºäºå…¨å±€æ¢¯åº¦ï¼ˆ8 ä¸ª GPU çš„åˆå¹¶æ¢¯åº¦ï¼‰
- æ‰€æœ‰è¿›ç¨‹ä½¿ç”¨ç›¸åŒçš„ä¼˜åŒ–å™¨å­¦ä¹ ç‡

### 3. åŒæ­¥æ£€æŸ¥ç‚¹

- æ‰€æœ‰è¿›ç¨‹åœ¨ episode ç»“æŸååŒæ­¥ï¼ˆ`torch.distributed.barrier()`ï¼‰
- åªæœ‰ rank 0 è¿›ç¨‹ä¿å­˜æ¨¡å‹ï¼Œé¿å…æ–‡ä»¶å†²çª
- åªæœ‰ rank 0 è¿›ç¨‹è¾“å‡ºæ—¥å¿—ï¼Œå‡å°‘æ§åˆ¶å°è¾“å‡º

### 4. æ•°æ®ä¸€è‡´æ€§

- æ‰€æœ‰è¿›ç¨‹åˆå§‹åŒ–ç§å­ç›¸åŒï¼ˆ`seed=1`ï¼‰
- ç¯å¢ƒçŠ¶æ€åŒæ­¥
- ç»éªŒå›æ”¾ç¼“å†²åŒºç‹¬ç«‹ï¼ˆæ¯ä¸ªè¿›ç¨‹ç»´æŠ¤è‡ªå·±çš„ç¼“å†²åŒºï¼‰

---

## æ€§èƒ½å¯¹æ¯”

### å•å¡ vs 8 å¡

| æŒ‡æ ‡ | å•å¡ (V100) | 8 å¡ (V100) |
|------|-----------|-----------|
| æ¢¯åº¦è®¡ç®— | 1x | ~7.8x |
| æ ·æœ¬æ”¶é›† | 1x | ~1x* |
| æ€»ä½“åŠ é€Ÿ | 1x | ~4-6x |
| å†…å­˜å ç”¨ | ~10GB | ~12GB per GPU |
| é€šä¿¡å¼€é”€ | 0 | ~5-10% |

*æ ·æœ¬æ”¶é›†ä¸åŠ é€Ÿæ˜¯å› ä¸ºç¯å¢ƒæ˜¯å•è¿›ç¨‹çš„ï¼ˆæ¸¸æˆç¯å¢ƒé€šå¸¸éš¾ä»¥å¹¶è¡ŒåŒ–ï¼‰

### é¢„æœŸæ•ˆæœ

- **è®­ç»ƒé€Ÿåº¦**ï¼š4-6 å€åŠ å¿«ï¼ˆä¸»è¦å—ç¯å¢ƒæ¨¡æ‹Ÿé™åˆ¶ï¼‰
- **æ€»æ ·æœ¬é‡**ï¼šç›¸åŒ episode ä¸‹ï¼Œæ¢¯åº¦æ›´æ–°æ›´é¢‘ç¹
- **æ”¶æ•›é€Ÿåº¦**ï¼šå¯èƒ½ç•¥æœ‰æ”¹å–„ï¼ˆæ›´å¤šæ¢¯åº¦æ›´æ–°ï¼‰
- **æœ€ç»ˆæ€§èƒ½**ï¼šä¸å•å¡ç›¸åŒï¼ˆè®­ç»ƒé€»è¾‘å®Œå…¨ç›¸åŒï¼‰

---

## æ•…éšœæ’æŸ¥ (Troubleshooting)

### é—®é¢˜ 1ï¼šCUDA out of memory

```
RuntimeError: CUDA out of memory. Tried to allocate X.00 GiB
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å‡å°‘ batch_size
torchrun --nproc_per_node=8 rl_trainer/main_ddp.py --batch_size 64

# å‡å°‘ buffer_size
torchrun --nproc_per_node=8 rl_trainer/main_ddp.py --buffer_size 50000
```

### é—®é¢˜ 2ï¼šè¿›ç¨‹æŒ‚èµ· (Process hangs)

**åŸå› **ï¼šè¿›ç¨‹åœ¨ `barrier()` å¤„å¡ä½ï¼Œé€šå¸¸æ˜¯å› ä¸ºæŸäº›è¿›ç¨‹å´©æºƒ

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥æ—¥å¿—ä¸­çš„é”™è¯¯ä¿¡æ¯
- å°è¯•åœ¨ rank 0 çœ‹åˆ°é”™è¯¯åä½¿ç”¨ `Ctrl+C` å¼ºåˆ¶ç»ˆæ­¢

### é—®é¢˜ 3ï¼šGPU æ˜¾å­˜ä¸è¶³å‡è¡¡

**ç°è±¡**ï¼šæŸä¸ª GPU æ˜¾å­˜æ»¡ï¼Œå…¶ä»– GPU é—²ç½®

**åŸå› **ï¼šç»éªŒå›æ”¾ç¼“å†²åŒºåˆ†å¸ƒä¸å‡åŒ€

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å‡å°‘ `--buffer_size`
- å‡å°‘ `--batch_size`

### é—®é¢˜ 4ï¼šæ¨¡å‹åŠ è½½å¤±è´¥

```
Model not founded at rl_trainer/models/...
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ç¡®ä¿å•å¡è®­ç»ƒå·²ç”Ÿæˆæ¨¡å‹æ–‡ä»¶
- æ£€æŸ¥ `--load_model_run` å’Œ `--load_model_run_episode` å‚æ•°
- ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨äº `rl_trainer/models/snakes_3v3/run{N}/trained_model/`

---

## æ—¥å¿—å’Œç»“æœ

### æ—¥å¿—ä½ç½®

```
rl_trainer/runs/snakes_3v3/
â”œâ”€â”€ run1_YYYYMMDD_HHMMSS/
â”‚   â”œâ”€â”€ trained_model/
â”‚   â”‚   â”œâ”€â”€ actor_1000.pth
â”‚   â”‚   â”œâ”€â”€ critic_1000.pth
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ events.*  # TensorBoard æ—¥å¿—
â”œâ”€â”€ run2_YYYYMMDD_HHMMSS/
â””â”€â”€ ...
```

### æŸ¥çœ‹è®­ç»ƒæ›²çº¿

```bash
# å¯åŠ¨ TensorBoard
tensorboard --logdir=rl_trainer/runs/snakes_3v3

# ç„¶ååœ¨æµè§ˆå™¨æ‰“å¼€ http://localhost:6006
```

### æ§åˆ¶å°è¾“å‡º

åªæœ‰ rank 0 è¿›ç¨‹è¾“å‡ºæ—¥å¿—ï¼š

```
[Episode 00001] total_reward: 45 epsilon: 0.50 [v3.0] difficulty: 0
        snake_1: 15 snake_2: 15 snake_3: 15
        a_loss 0.123 c_loss 0.456
```

---

## ä¸å•å¡ç‰ˆæœ¬çš„å¯¹æ¯”

### ä»£ç æ”¹åŠ¨åŸåˆ™

âœ… **æ–°å¢æ–‡ä»¶**ï¼ˆæ— ä»»ä½•å½±å“ï¼‰ï¼š
- `rl_trainer/algo/ddpg_ddp.py`
- `rl_trainer/main_ddp.py`
- `train_ddp.sh`
- `README_DDP.md`

âœ… **åŸæœ‰æ–‡ä»¶ä¿æŒä¸å˜**ï¼š
- `rl_trainer/main.py`
- `rl_trainer/algo/ddpg.py`
- `rl_trainer/common.py`
- æ‰€æœ‰å…¶ä»–æ–‡ä»¶

### åˆ‡æ¢ç‰ˆæœ¬

```bash
# å•å¡è®­ç»ƒï¼ˆåŸå§‹ç‰ˆæœ¬ï¼‰
python rl_trainer/main.py

# 8 å¡åˆ†å¸ƒå¼è®­ç»ƒï¼ˆæ–°ç‰ˆæœ¬ï¼‰
torchrun --nproc_per_node=8 rl_trainer/main_ddp.py
```

---

## é«˜çº§ç”¨æ³•

### åœ¨ SLURM é›†ç¾¤ä¸Šè¿è¡Œ

```bash
#!/bin/bash
#SBATCH --job-name=snake_ddp
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=8
#SBATCH --gpus-per-node=8
#SBATCH --time=24:00:00

torchrun --nproc_per_node=8 rl_trainer/main_ddp.py \
  --max_episodes 100000 \
  --opponent_difficulty_strategy curriculum
```

### ç›‘æ§ GPU ä½¿ç”¨

```bash
# å®æ—¶ç›‘æ§ GPU çŠ¶æ€
watch -n 1 nvidia-smi

# æˆ–è€…å®šæœŸæ£€æŸ¥
while true; do nvidia-smi; sleep 10; done
```

### è°ƒè¯•åˆ†å¸ƒå¼è®­ç»ƒ

```bash
# å¯ç”¨ debug æ—¥å¿—
NCCL_DEBUG=INFO torchrun --nproc_per_node=8 rl_trainer/main_ddp.py

# æ£€æŸ¥è¿›ç¨‹é€šä¿¡
NCCL_DEBUG=TRACE torchrun --nproc_per_node=8 rl_trainer/main_ddp.py
```

---

## FAQ

**Q: DDP ç‰ˆæœ¬å’Œå•å¡ç‰ˆæœ¬çš„ç»“æœä¼šä¸åŒå—ï¼Ÿ**

A: ä¸ä¼šã€‚è®­ç»ƒé€»è¾‘å®Œå…¨ç›¸åŒï¼Œåªæ˜¯æ¢¯åº¦æ›´æ–°æ›´é¢‘ç¹ï¼ˆå› ä¸ºæœ‰ 8 ä¸ª GPU å¹¶è¡Œè®¡ç®—ï¼‰ã€‚æœ€ç»ˆæ”¶æ•›ç»“æœåº”è¯¥ç›¸åŒæˆ–æ›´å¥½ã€‚

**Q: å¯ä»¥ä½¿ç”¨å°‘äº 8 å¡å—ï¼Ÿ**

A: å¯ä»¥ã€‚åªéœ€ä¿®æ”¹ `--nproc_per_node` çš„å€¼ï¼Œæ¯”å¦‚ï¼š
```bash
torchrun --nproc_per_node=4 rl_trainer/main_ddp.py
```

**Q: å¯ä»¥åœ¨å¤šå°æœºå™¨ä¸Šè¿è¡Œå—ï¼Ÿ**

A: å¯ä»¥ï¼Œä½†éœ€è¦é¢å¤–é…ç½®ï¼ˆå‚è€ƒ PyTorch å®˜æ–¹æ–‡æ¡£ï¼‰ã€‚å•æœºå¤šå¡ä½¿ç”¨æœ¬æŒ‡å—ã€‚

**Q: å†…å­˜å ç”¨ä¼šå¢åŠ å—ï¼Ÿ**

A: æ¯ä¸ª GPU ä¸Šçš„æ¨¡å‹å¤§å°ç›¸åŒï¼Œä½†æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€ä¼šé‡å¤ã€‚æ€»ä½“å†…å­˜å ç”¨çº¦ä¸ºå•å¡çš„ 1.2 å€ã€‚

**Q: å¦‚ä½•æ¢å¤ä¸­æ–­çš„è®­ç»ƒï¼Ÿ**

A: ä½¿ç”¨ `--load_model` å‚æ•°ï¼š
```bash
torchrun --nproc_per_node=8 rl_trainer/main_ddp.py \
  --load_model \
  --load_model_run 1 \
  --load_model_run_episode 50000
```

---

## å‚è€ƒèµ„æº

- [PyTorch DDP å®˜æ–¹æ–‡æ¡£](https://pytorch.org/docs/stable/distributed.html)
- [Torch.run å¯åŠ¨å™¨](https://pytorch.org/docs/stable/elastic/run.html)
- [åˆ†å¸ƒå¼è®­ç»ƒæœ€ä½³å®è·µ](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)

---

## è®¸å¯è¯

æœ¬ DDP ç‰ˆæœ¬éµå¾ªåŸé¡¹ç›®çš„è®¸å¯è¯ã€‚

---

**æœ€åæ›´æ–°**: 2024 å¹´ 11 æœˆ
**ç‰ˆæœ¬**: 1.0
**ä½œè€…**: Generated with Claude Code
